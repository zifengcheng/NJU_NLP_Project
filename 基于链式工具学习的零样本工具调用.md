# 基于链式工具学习的零样本工具调用
### 一、背景要求
近年来，随着大规模预训练语言模型（LLM）的兴起，其强大的语义理解与推理能力已在问答、文本生成、信息抽取等任务中得到广泛应用。然而，LLM在执行特定操作（如精确计算、数据库查询、API 调用）时存在局限。**Chain-of-Tools (CoTools)** 方法利用“工具调用”（Tool Learning）将外部功能接口（计算、检索、知识库访问等）无缝嵌入 LLM 的生成过程，实现了：

+ **工具判断（Tool Judge）**：模型在生成时刻决定是否调用工具；
+ **工具检索（Tool Retriever）**：基于隐藏态对海量工具进行高效检索；
+ **工具调用（Tool Calling）**：填充参数并执行所选工具，将结果加入回答。

但在 **海量、未见**（unseen）工具场景下，如何保持调用正确率且兼顾推理成本，仍是关键挑战。  

本次大作业基于 CoTools 方法，要求同学们实现从工具判断到调用的完整流水线，并在数值推理与知识问答两类任务上验证效果；同时设计创新方案，提升效率或性能。

---

### 二、方法介绍
1. **工具判断（Tool Judge）**  
    - 输入：LM 在生成下一个 token 时的隐藏态 ![image](https://cdn.nlark.com/yuque/__latex/ca57d16acf441271e4e8283f344a3f70.svg)  
    - 输出：调用概率 ![image](https://cdn.nlark.com/yuque/__latex/f6be8bb0e6b85eda77cb21c1c3e312fb.svg)  
    - 实现：基于双层线性＋Gating，自定义阈值控制是否发起工具检索。
2. **工具检索（Tool Retriever）**  
    - 将检索上下文（查询＋当前回答片段）末尾的隐藏态映射为**查询向量** ![image](https://cdn.nlark.com/yuque/__latex/4a1866ab88ebd416681c427f54504d94.svg)；  
    - 对每个工具描述末尾隐藏态映射为**工具向量** ![image](https://cdn.nlark.com/yuque/__latex/7e66fe7dac4b306efd6e109b532510dc.svg)；  
    - 通过对比学习（contrastive learning）训练，使得正确工具对的余弦相似度最高；推理时取 ![image](https://cdn.nlark.com/yuque/__latex/10a7c6eae8f909fee11c89d9f1a6042d.svg)。
3. **工具调用（Tool Calling）**  
    - 利用 ICL Prompt 填充参数格式（正则提取）并执行（如调用 Python 函数、外部 API 等）；  
    - 将返回值拼接到生成文本中，继续后续推理。

---

### 三、任务描述
#### 3.1 简单任务（60 分 = 结果准确性 40 + 报告质量 20）
+ **任务目标**  
    - **（A）数值推理子任务**：在 GSM8K-XL 与 FuncQA 上实现 CoTools 完整流程；  
        * 实现 Tool Judge 与 Tool Retriever，支持基础算术工具（加减乘除、函数库）；  
        * 验证对比学习策略在 one-hop 与 multi-hop 计算上的准确率提升。
    - **（B）知识问答子任务**：在 KAMEL 与 STQuestions 上评估工具选择准确率；  
        * 统计 Seen/Unseen 工具 Top‑1／Top‑5 精度。
+ **评估指标**  
    - 数值推理：Round Accuracy（精确到两位小数）、Approx Accuracy（多步容错 0.1%）；  
    - KBQA：工具选择正确率（Top‑1/Top‑5）。

#### 3.2 进阶任务（40 分 = 创新性 20 + 性能 & 资源 10 + 报告质量 10）
+ **设计并实现一种或多种创新方案**，例如但不限于：
    1. **层次化检索**：先粗排再精排，减少候选工具计算量；  
    2. **自适应调用策略**：基于当前 token 位置动态调整调用阈值 θ；  
    3. **轻量化表示**：在维度选择（W<sub>dim</sub>）或剪枝后，加速检索；  
    4. **复合工具链**：组合多工具调用，解决复杂多步任务。
+ **要求**  
    - 在排序准确率或工具选择精度上超越基础 CoTools（All‑Pair）；  
    - 明确说明计算开销（推理时间、内存、API 调用次数）对比。

---

### 四、实验设置及评估
1. **硬件环境**：建议使用至少一块 16 GB GPU；  
2. **框架与依赖**：PyTorch、Transformers；可选 Accelerate 或 DeepSpeed；  
3. **数据准备**：论文中附带的 GSM8K‑XL、FuncQA、KAMEL、STQuestions 数据集；  
4. **超参建议**：  
    - Judge 学习率 1e‑5，Epoch 3；Retriever 学习率 1e‑4，Epoch 10；  
    - 对比学习批量大小 16，负采样为同批次其它工具；
5. **日志与复现**：提供训练／评估脚本、随机种子、日志及模型权重链接。

---

### 五、提交要求
1. **完整代码**（压缩包）：  
    - 包含 Tool Judge、Tool Retriever、Tool Calling 实现；  
    - `train.py`、`evaluate.py`、`predict.py` 脚本；
2. **实验报告**（PDF）：  
    - 任务背景与方法简介；  
    - 实现细节（模型结构、对比学习损失、检索优化等）；  
    - 实验结果对比分析（表格、曲线）；  
    - 进阶方案设计与评估；
3. **项目演示**（可选）：短视频或 PPT 演示核心思路；  
4. **参考文献**：按照学术规范列出所用文献。

---

### 六、注意事项
+ **学术诚信**：严禁抄袭，引用他人工作务必注明；  
+ **代码规范**：模块化、注释清晰，可读性强；  
+ **联系方式**：如有疑问，请联系 qianly@smail.nju.edu.cn；  



---

