# 从大语言模型中抽取句子嵌入

---

本次大作业要求从大语言模型（LLM）中提取句子嵌入（sentence embedding）。具体方法是借助提示（prompt），鼓励大模型将句子的深层语义信息高效地压缩至一个 token 级别的向量中，并进行分析实验和进一步探索使用提示工程和激活工程来提升句子嵌入的质量。有些实验任务需要注意可解释性。

---
## 一、背景要求

当前，大语言模型在零样本自然语言处理领域展现了强大的语义理解能力，推动了文本表示技术的不断革新。从大模型中抽取句子嵌入是一个具有潜力的方向，因为它既不需要额外数据也不需要额外训练。利用提示工程引导大模型将句子浓缩为单个 token 的向量是当前常用的方法，但提示工程方法仍然是经验性的，并且存在一些不足。本次大作业希望在提示工程的基础上，进行进一步探索并且解释。

---

## 二、基于提示工程的抽取方法介绍

基于提示工程的抽取方法主要依赖于设计精妙的提示模板，以引导大语言模型在解码过程中直接生成具备代表性的句子嵌入。本作业中给出了三种提示模板：PromptEOL（Prompt-based method with Explicit One word Limitation）、CoT（Pretended Chain of Thought）、KE（Knowledge Enhancement），都是鼓励大模型将句子语义编码到提示的最后一个token中，CoT和KE分别在PromptEOL的基础上，引入了伪思维链和知识增强来强化大模型对句子核心语义的关注。然而，现有提示工程的方法仍然编码了与句子语义无关的信息。

---
## 三、激活工程的介绍

激活工程是对一个输入在大模型内部运行时的激活值进行调整，以引导大模型的行为符合预期。具体而言，输入数据在通过大模型的特定模块时，改变模块输入或输出以进行干预，比如在第1层的输出上进行干预，将”悲伤“的激活值加到”小明看了一个笑话，他“的激活值上，会使模型生成的下一个token是负面情绪词。

这种方法关注的不再仅仅是输入提示的文字表述，而是深入到模型内部的“黑箱”中进行调节。但同时，其挑战也不容忽视：模型内部激活值具有高度非线性，识别关键节点并精确调控困难；干预可能引发连锁反应，导致输出不稳定或偏差；需要在提示工程与激活工程之间寻找有效协同，确保整体输出与输入语义一致。

更多信息可以参考论文：STEERING LANGUAGE MODELS WITH ACTIVATION ENGINEERING。除此之外，还有更多关于激活工程的论文。

---

## 四、任务描述

本次实验采用 **STS Dataset**，作业任务分为两个任务，内容如下：

### 4.1 简单任务（40分 = 结果准确性30分 + 报告质量10分）

- **任务内容**：
- **使用提示抽取句子嵌入**：使用PromptEOL、CoT、KE抽取句子嵌入进行评估。
- **探索大模型不同层的句子嵌入质量**：探索使用PromptEOL抽取不同层对句子嵌入表现的影响
- **提示模板参考**，其中text是句子的占位符：
	- PromptEOL：This sentence : ”[text] ” means in one word: “
	- CoT：After thinking step by step , this sentence : “ [text] ” means in one word: “
	- KE：The essence of a sentence is often captured by its main subjects and actions, while descriptive terms provide additional but less central details. With this in mind , this sentence : “ [text] ” means in one word: “
	
### 4.2 分析任务 （20分 = 创新性10分 + 报告质量10分）

请从以下两个中选择一个：
1. 设计一个或者一类新的提示效果超过PromptEOL并且能直观地解释其为何有效。
2. 使用PromptEOL对句子进行压缩时，观察并分析模型解码的下一个token是否倾向于句子的第一个token或单词。通过选取多种不同类型的句子，调查这一现象是否普遍存在，并尝试解释其成因。所选句子类型应涵盖句法结构（如简单句、并列句）、语义结构（如隐喻、象征）、情感倾向、语用种类（如陈述、疑问）、句子长度等方面，且句子种类不少于10个。如果能把这现象进行应用以提升性能，可以给一些bonus，总分不超过100。

### 4.3 进阶任务 （40分 = 创新性20分 + 报告质量20分）

请从以下两个中选择一个：
1. 使用PromptEOL，基于Qwen2.5-7B-Instruct抽取27层的句子嵌入，在STSB数据集上测试分数为75.23，在模型的第二层对每个激活值乘以1.5可以使分数涨到76.8。尝试解释此现象并给出原因。基于该原因，探索一个更优雅的抽取句子嵌入的解决方案。
2. 设计激活工程或者模型内部操作方法提升PromptEOL的性能，比如注意力干预，提示对比。


---

## 五、提交要求

提交内容包括：

1. **完整代码文件**：将所有代码文件打包提交，包含实现使用提示工程抽取句子嵌入进行评估的代码以及进阶任务的代码。
    
2. **实验报告（PDF）**
    
## 六、注意事项

1. **参考文献**：
    
    - 如果你在实验和报告中参考了已发表的文献，请列出你所参考的相关文献。
2. [数据](https://box.nju.edu.cn/f/a5404f25661d456c8b15/?dl=1)可以从上面的链接下载。
    
3. 如有疑问，请联系 chengzf@smail.nju.edu.cn。
